{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx76qjaGKwIS"
   },
   "source": [
    "# 既存資料からチャットボットを作成する(Retrieval Augumented Generation:RAG)\n",
    "\n",
    "- 参考\n",
    "  - https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb\n",
    "  - https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
    "  - https://note.com/mahlab/n/nb6677d0fc7c2\n",
    "- Chromadbがすごい\n",
    "  - https://www.trychroma.com/\n",
    "  - https://github.com/chroma-core/chroma\n",
    "- ChatGPTのSurvey論文\n",
    "  - https://arxiv.org/pdf/2304.01852.pdf\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6477,
     "status": "ok",
     "timestamp": 1744862988591,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "fC7q6QnDPIW2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "import openai\n",
    "import os\n",
    "# langchain-openai パッケージからインポート\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1744862993307,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "SZEvBNCdPxmp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m openai.api_key = \u001b[43mos\u001b[49m.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 18069,
     "status": "ok",
     "timestamp": 1744863035248,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "1RVC0SOUL1Dp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDocument\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, metadata):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "dir_path = \"loadtext/\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3637,
     "status": "ok",
     "timestamp": 1744863063789,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "oamHbgKbRBFI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m text_splitter = \u001b[43mRecursiveCharacterTextSplitter\u001b[49m(chunk_size=\u001b[32m1000\u001b[39m, chunk_overlap=\u001b[32m0\u001b[39m)\n\u001b[32m      2\u001b[39m texts = text_splitter.split_documents(documents)\n\u001b[32m      3\u001b[39m embeddings = OpenAIEmbeddings()\n",
      "\u001b[31mNameError\u001b[39m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14384,
     "status": "ok",
     "timestamp": 1744863080365,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "duuXVCZlwPst",
    "outputId": "8af590ce-4923-438d-e7cd-179db285c54f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 質問を作成するために invoke メソッドを使用\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m questions = \u001b[43mqa\u001b[49m.invoke(\u001b[33m\"\u001b[39m\u001b[33mこの文章の中で重要ど思う線形代数に関する内容についてを考える質問を10個考えてください\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 結果の表示\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(questions[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "# 質問を作成するために invoke メソッドを使用\n",
    "questions = qa.invoke(\"この文章の中で重要ど思う線形代数に関する内容についてを考える質問を10個考えてください\")\n",
    "\n",
    "# 結果の表示\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4227,
     "status": "ok",
     "timestamp": 1744863124931,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "WuiXiS92vWju",
    "outputId": "9c8efc9e-76ec-450a-f479-ef2af65b4efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すみませんが、提供された情報には疑似逆行列についての説明は含まれていません。したがって、その質問には答えられません。\n"
     ]
    }
   ],
   "source": [
    "# 質問を作成するために invoke メソッドを使用\n",
    "questions = qa.invoke(\"疑似逆行列とは何ですか？検索できなければわからないと答えてください。\")\n",
    "\n",
    "# 結果の表示\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "executionInfo": {
     "elapsed": 15160,
     "status": "ok",
     "timestamp": 1744863145195,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "wh0jw-neN2kc",
    "outputId": "ba4b2d47-dad7-45da-afb8-fbb12ce02f64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamadayuuhei/研究/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://3b9d32932ce89b4d3c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3b9d32932ce89b4d3c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インポート\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ドキュメントをロード\n",
    "dir_path = 'loadtext/'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "\n",
    "# ドキュメントの分割とベクトルDBの作成\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAチェーンの作成\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# チャット機能の実装\n",
    "def chat_with_ai(input_text):\n",
    "    response = qa.invoke(input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。')\n",
    "    return response['result']\n",
    "\n",
    "# Gradioインターフェースの設定\n",
    "iface = gr.Interface(\n",
    "    fn=chat_with_ai,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"AI Chat with Gradio\",\n",
    "    description=\"OpenAIを使ったチャットインターフェース\"\n",
    ")\n",
    "\n",
    "# インターフェースの起動\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 11785,
     "status": "ok",
     "timestamp": 1721112692893,
     "user": {
      "displayName": "中西崇文",
      "userId": "05356289898840747459"
     },
     "user_tz": -540
    },
    "id": "1DBYaPehIXn4",
    "outputId": "41675b6c-0c96-4446-e22f-25ab82f6b930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/n3nkdz2558g2zjbwzth6xy700000gn/T/ipykernel_35474/350495278.py:58: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
      "/Users/yamadayuuhei/研究/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/gradio/chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 16:00:02 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: i/o timeout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インポート\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ドキュメントをロードするクラス\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "# ドキュメントをロード（例としてテキストを使用）\n",
    "dir_path = 'loadtext2'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "# ドキュメントの分割とベクトルDBの作成\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAチェーンの作成\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# チャット機能の実装\n",
    "def chat_with_ai(input_text, history):\n",
    "    response = qa({\"query\": input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。'})\n",
    "    return response['result']\n",
    "\n",
    "# GradioのChatInterfaceを使用してインターフェースを作成\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
    "    gr.Markdown(\"### AI Chat with Gradio\")\n",
    "\n",
    "# インターフェースの起動\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c222aoDCM8Qj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMfrYF6ow3Du/BqoD+S8ar9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
