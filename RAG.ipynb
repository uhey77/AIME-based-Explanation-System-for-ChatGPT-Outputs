{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx76qjaGKwIS"
   },
   "source": [
    "# 既存資料からチャットボットを作成する(Retrieval Augumented Generation:RAG)\n",
    "\n",
    "- 参考\n",
    "  - https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb\n",
    "  - https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
    "  - https://note.com/mahlab/n/nb6677d0fc7c2\n",
    "- Chromadbがすごい\n",
    "  - https://www.trychroma.com/\n",
    "  - https://github.com/chroma-core/chroma\n",
    "- ChatGPTのSurvey論文\n",
    "  - https://arxiv.org/pdf/2304.01852.pdf\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 75356,
     "status": "ok",
     "timestamp": 1744862875203,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "Pmpfw-x7Kt7H"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 必要なパッケージをインストール\n",
    "!pip install -U langchain-community\n",
    "!pip install openai\n",
    "# 残りのコードをここに追加\n",
    "!pip install --upgrade chromadb langchain\n",
    "!pip install pypdf\n",
    "!pip install tiktoken\n",
    "!pip install gradio\n",
    "!pip install pypdf2\n",
    "!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6477,
     "status": "ok",
     "timestamp": 1744862988591,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "fC7q6QnDPIW2"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "import openai\n",
    "import os\n",
    "# langchain-openai パッケージからインポート\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1744862990934,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "zdTC8km-OpiG"
   },
   "outputs": [],
   "source": [
    "API_KEY=\"XXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1744862993307,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "SZEvBNCdPxmp"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17163,
     "status": "ok",
     "timestamp": 1744863012438,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "wtAj70MKOlRQ",
    "outputId": "b838d56c-791e-411a-c1d8-3bbb8ac2382e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18069,
     "status": "ok",
     "timestamp": 1744863035248,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "1RVC0SOUL1Dp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "dir_path = \"/content/drive/MyDrive/ユニークAIシステム構築道場/RAG/loadtext/\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3637,
     "status": "ok",
     "timestamp": 1744863063789,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "oamHbgKbRBFI"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14384,
     "status": "ok",
     "timestamp": 1744863080365,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "duuXVCZlwPst",
    "outputId": "8af590ce-4923-438d-e7cd-179db285c54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 線形代数における「線形写像」は何を意味しますか？\n",
      "2. ベクトルと行列ではどのような計算や操作が可能ですか？\n",
      "3. 具体的に、線形変換や行列の積（写像の合成）をする際の計算手順は何ですか？\n",
      "4. コサイン類似度の計算に線形代数のどの部分が用いられますか？\n",
      "5. 線形代数における「核(Ker)」とは何ですか？\n",
      "6. Pythonで線形代数の計算を行う場合、どのようなライブラリやメソッドが利用可能ですか？\n",
      "7. 線形代数がデータサイエンス等の実用的な応用分野でどのように用いられますか？\n",
      "8. 「連立一次方程式」はどのように解くことができますか？\n",
      "9. 「連立一次方程式」をベクトルと行列を用いて表現することは何を可能にしますか？\n",
      "10. ベクトルや行列、線形変換等の数学的な概念を体系的に学ぶことで得られる利点は何ですか？\n"
     ]
    }
   ],
   "source": [
    "# 質問を作成するために invoke メソッドを使用\n",
    "questions = qa.invoke(\"この文章の中で重要ど思う線形代数に関する内容についてを考える質問を10個考えてください\")\n",
    "\n",
    "# 結果の表示\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4227,
     "status": "ok",
     "timestamp": 1744863124931,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "WuiXiS92vWju",
    "outputId": "9c8efc9e-76ec-450a-f479-ef2af65b4efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私の知識からは、疑似逆行列についての情報を提供することはできません。お手数をおかけしますが、それについては別の情報源をご覧になるか、専門家に問い合わせてください。\n"
     ]
    }
   ],
   "source": [
    "# 質問を作成するために invoke メソッドを使用\n",
    "questions = qa.invoke(\"疑似逆行列とは何ですか？検索できなければわからないと答えてください。\")\n",
    "\n",
    "# 結果の表示\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "executionInfo": {
     "elapsed": 15160,
     "status": "ok",
     "timestamp": 1744863145195,
     "user": {
      "displayName": "中西崇文",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "wh0jw-neN2kc",
    "outputId": "ba4b2d47-dad7-45da-afb8-fbb12ce02f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://d070f60ce52cdb6e86.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d070f60ce52cdb6e86.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インポート\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ドキュメントをロード\n",
    "dir_path = '/content/drive/MyDrive/ユニークAIシステム構築道場/RAG/loadtext/'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "\n",
    "# ドキュメントの分割とベクトルDBの作成\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAチェーンの作成\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# チャット機能の実装\n",
    "def chat_with_ai(input_text):\n",
    "    response = qa.invoke(input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。')\n",
    "    return response['result']\n",
    "\n",
    "# Gradioインターフェースの設定\n",
    "iface = gr.Interface(\n",
    "    fn=chat_with_ai,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"AI Chat with Gradio\",\n",
    "    description=\"OpenAIを使ったチャットインターフェース\"\n",
    ")\n",
    "\n",
    "# インターフェースの起動\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtOXlLBeFp5y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 11785,
     "status": "ok",
     "timestamp": 1721112692893,
     "user": {
      "displayName": "中西崇文",
      "userId": "05356289898840747459"
     },
     "user_tz": -540
    },
    "id": "1DBYaPehIXn4",
    "outputId": "41675b6c-0c96-4446-e22f-25ab82f6b930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://135cc0aa561ecf76f8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://135cc0aa561ecf76f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インポート\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ドキュメントをロードするクラス\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "# ドキュメントをロード（例としてテキストを使用）\n",
    "dir_path = '/content/drive/MyDrive/Colab Notebooks/CollaborativeResearch/BandaiLogipal/BasicChat/loadtext2'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFファイルを読み込む\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # テキストファイルを読み込む\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "# ドキュメントの分割とベクトルDBの作成\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAチェーンの作成\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# チャット機能の実装\n",
    "def chat_with_ai(input_text, history):\n",
    "    response = qa({\"query\": input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。'})\n",
    "    return response['result']\n",
    "\n",
    "# GradioのChatInterfaceを使用してインターフェースを作成\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
    "    gr.Markdown(\"### AI Chat with Gradio\")\n",
    "\n",
    "# インターフェースの起動\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c222aoDCM8Qj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMfrYF6ow3Du/BqoD+S8ar9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
