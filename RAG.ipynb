{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx76qjaGKwIS"
   },
   "source": [
    "# æ—¢å­˜è³‡æ–™ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œæˆã™ã‚‹(Retrieval Augumented Generation:RAG)\n",
    "\n",
    "- å‚è€ƒ\n",
    "  - https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb\n",
    "  - https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
    "  - https://note.com/mahlab/n/nb6677d0fc7c2\n",
    "- ChromadbãŒã™ã”ã„\n",
    "  - https://www.trychroma.com/\n",
    "  - https://github.com/chroma-core/chroma\n",
    "- ChatGPTã®Surveyè«–æ–‡\n",
    "  - https://arxiv.org/pdf/2304.01852.pdf\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6477,
     "status": "ok",
     "timestamp": 1744862988591,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "fC7q6QnDPIW2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chromadb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# langchain-openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m     13\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "import openai\n",
    "import os\n",
    "# langchain-openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1744862993307,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "SZEvBNCdPxmp"
   },
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 18069,
     "status": "ok",
     "timestamp": 1744863035248,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "1RVC0SOUL1Dp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "dir_path = \"loadtext/\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3637,
     "status": "ok",
     "timestamp": 1744863063789,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "oamHbgKbRBFI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[0;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m      4\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(texts, embeddings)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14384,
     "status": "ok",
     "timestamp": 1744863080365,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "duuXVCZlwPst",
    "outputId": "8af590ce-4923-438d-e7cd-179db285c54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. æ•™ç§‘æ›¸ã®p.62ã€œp.106ãƒšãƒ¼ã‚¸ã§å–ã‚Šä¸Šã’ã‚‰ã‚Œã¦ã„ã‚‹ç·šå½¢ä»£æ•°ã®ä¸»ãªå†…å®¹ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
      "2. æ•™æã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹YouTubeã®prof.Gilbert Strangã®ç·šå½¢ä»£æ•°æˆæ¥­ã€Œ1. The Geometry of Linear Equationsã€ã®ä¸»è¦ãªæ•™è¨“ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
      "3. å†™åƒã®åˆæˆã¨ã¯ä½•ã§ã™ã‹ã€ãã®ä¸­ã§ç·šå½¢å¤‰æ›ğ‘“ã¨ğ‘”ã®åˆæˆãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n",
      "4. ç·šå½¢å¤‰æ›ğ‘“ã«ã‚ˆã£ã¦ğ‘…ã®ãƒ™ã‚¯ãƒˆãƒ«ğ’™ã‚’ğ‘…ã®ãƒ™ã‚¯ãƒˆãƒ«ğ‘“ğ’™ã«å¤‰æ›ã—ãŸã‚ã¨ã€ãã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã•ã‚‰ã«ç·šå½¢å¤‰æ›ğ‘”ã«ã‚ˆã£ã¦ğ‘…ã®ãƒ™ã‚¯ãƒˆãƒ«ğ‘”(ğ‘“ğ’™)ã«å¤‰æ›ã™ã‚‹ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã®é‡è¦æ€§ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n",
      "5. ğ’™ğ´ğ’™ğµğ´ğ’™ğ´ğµâ‰ ğµğ´ã¨ã¯ã©ã†ã„ã†æ„å‘³ã§ã™ã‹ï¼Ÿ\n",
      "6. èª²é¡Œä¸­ã®å˜ç´”ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã®è¡¨ç¾ ğ’š=ğ’˜$ğ’™+ğ‘ã‹ã‚‰ ğ’š=ğ’˜$ğ’™ã¸ç§»è¡Œã™ã‚‹éš›ã®ãƒã‚¤ã‚¢ã‚¹é …(+ğ‘)ã®å½¹å‰²ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
      "7. Lec02.ipynbã®ã€Œå…¥åŠ›ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸­ã®ç”»åƒã‹ã‚‰ä¸€ç•ªé¡ä¼¼æ€§ãŒé«˜ã„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¤œç´¢ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã®éƒ¨åˆ†ã«ãŠã‘ã‚‹ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®è¨ˆç®—ã®é‡è¦æ€§ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
      "8. ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢ã€ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã€ãƒã‚§ãƒ“ã‚·ã‚§ãƒ•è·é›¢ã¨ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
      "9. ãƒ™ã‚¯ãƒˆãƒ«ã®æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆå€¤æ®µ850å††ã€é‡ã•1450gï¼‰ã®è¨ˆç®—æ–¹æ³•ã‚’èª¬æ˜ã§ãã¾ã™ã‹ï¼Ÿ\n",
      "10. æ•™ç§‘æ›¸p.114ã€œp.118ã§æ‰±ã‚ã‚Œã¦ã„ã‚‹ç·šå½¢ä»£æ•°ã®ä¸»é¡Œã¯ä½•ã§ã™ã‹ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# è³ªå•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã« invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨\n",
    "questions = qa.invoke(\"ã“ã®æ–‡ç« ã®ä¸­ã§é‡è¦ã©æ€ã†ç·šå½¢ä»£æ•°ã«é–¢ã™ã‚‹å†…å®¹ã«ã¤ã„ã¦ã‚’è€ƒãˆã‚‹è³ªå•ã‚’10å€‹è€ƒãˆã¦ãã ã•ã„\")\n",
    "\n",
    "# çµæœã®è¡¨ç¤º\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4227,
     "status": "ok",
     "timestamp": 1744863124931,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "WuiXiS92vWju",
    "outputId": "9c8efc9e-76ec-450a-f479-ef2af65b4efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã™ã¿ã¾ã›ã‚“ãŒã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«ã¯ç–‘ä¼¼é€†è¡Œåˆ—ã«ã¤ã„ã¦ã®èª¬æ˜ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã—ãŸãŒã£ã¦ã€ãã®è³ªå•ã«ã¯ç­”ãˆã‚‰ã‚Œã¾ã›ã‚“ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è³ªå•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã« invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨\n",
    "questions = qa.invoke(\"ç–‘ä¼¼é€†è¡Œåˆ—ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿæ¤œç´¢ã§ããªã‘ã‚Œã°ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "# çµæœã®è¡¨ç¤º\n",
    "print(questions['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "executionInfo": {
     "elapsed": 15160,
     "status": "ok",
     "timestamp": 1744863145195,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05483787995557177837"
     },
     "user_tz": -540
    },
    "id": "wh0jw-neN2kc",
    "outputId": "ba4b2d47-dad7-45da-afb8-fbb12ce02f64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamadayuuhei/ç ”ç©¶/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://3b9d32932ce89b4d3c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3b9d32932ce89b4d3c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "dir_path = 'loadtext/'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "\n",
    "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®ä½œæˆ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…\n",
    "def chat_with_ai(input_text):\n",
    "    response = qa.invoke(input_text+'æ¤œç´¢ã§ããŸç¯„å›²ã§ç­”ãˆã¦ãã ã•ã„ã€‚æ¤œç´¢ã§ããªã„ã‚‚ã®ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚')\n",
    "    return response['result']\n",
    "\n",
    "# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¨­å®š\n",
    "iface = gr.Interface(\n",
    "    fn=chat_with_ai,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"AI Chat with Gradio\",\n",
    "    description=\"OpenAIã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\"\n",
    ")\n",
    "\n",
    "# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 11785,
     "status": "ok",
     "timestamp": 1721112692893,
     "user": {
      "displayName": "ä¸­è¥¿å´‡æ–‡",
      "userId": "05356289898840747459"
     },
     "user_tz": -540
    },
    "id": "1DBYaPehIXn4",
    "outputId": "41675b6c-0c96-4446-e22f-25ab82f6b930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/n3nkdz2558g2zjbwzth6xy700000gn/T/ipykernel_35474/350495278.py:58: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
      "/Users/yamadayuuhei/ç ”ç©¶/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/gradio/chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 16:00:02 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: i/o timeout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import gradio as gr\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹\n",
    "class Document:\n",
    "    def __init__(self, text, metadata):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata\n",
    "\n",
    "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹ã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰\n",
    "dir_path = 'loadtext2'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    metadata = {'filename': filename}\n",
    "\n",
    "    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    if filename.endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = ''\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "    elif filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            documents.append(Document(text, metadata))\n",
    "\n",
    "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®ä½œæˆ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "\n",
    "# ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…\n",
    "def chat_with_ai(input_text, history):\n",
    "    response = qa({\"query\": input_text+'æ¤œç´¢ã§ããŸç¯„å›²ã§ç­”ãˆã¦ãã ã•ã„ã€‚æ¤œç´¢ã§ããªã„ã‚‚ã®ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚'})\n",
    "    return response['result']\n",
    "\n",
    "# Gradioã®ChatInterfaceã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆ\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
    "    gr.Markdown(\"### AI Chat with Gradio\")\n",
    "\n",
    "# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c222aoDCM8Qj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMfrYF6ow3Du/BqoD+S8ar9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
