{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx76qjaGKwIS"
      },
      "source": [
        "# 既存資料からチャットボットを作成する(Retrieval Augumented Generation:RAG)\n",
        "\n",
        "- 参考\n",
        "  - https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb\n",
        "  - https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
        "  - https://note.com/mahlab/n/nb6677d0fc7c2\n",
        "- Chromadbがすごい\n",
        "  - https://www.trychroma.com/\n",
        "  - https://github.com/chroma-core/chroma\n",
        "- ChatGPTのSurvey論文\n",
        "  - https://arxiv.org/pdf/2304.01852.pdf\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pmpfw-x7Kt7H"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# 必要なパッケージをインストール\n",
        "%pip install -U langchain-community\n",
        "%pip install openai\n",
        "# 残りのコードをここに追加\n",
        "%pip install -U chromadb langchain\n",
        "%pip install pypdf\n",
        "%pip install tiktoken\n",
        "%pip install gradio\n",
        "%pip install pypdf2\n",
        "%pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fC7q6QnDPIW2"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import VectorDBQA, RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "import openai\n",
        "import os\n",
        "# langchain-openai パッケージからインポート\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zdTC8km-OpiG"
      },
      "outputs": [],
      "source": [
        "API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SZEvBNCdPxmp"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
        "openai.api_key = API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1RVC0SOUL1Dp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, text, metadata):\n",
        "        self.page_content = text\n",
        "        self.metadata = metadata\n",
        "\n",
        "dir_path = r\"C:\\Users\\Takayama Ryuji\\Desktop\\g9\\loadtext\\loadtext\"\n",
        "\n",
        "documents = []\n",
        "\n",
        "for filename in os.listdir(dir_path):\n",
        "    file_path = os.path.join(dir_path, filename)\n",
        "    metadata = {'filename': filename}\n",
        "\n",
        "    # PDFファイルを読み込む\n",
        "    if filename.endswith('.pdf'):\n",
        "        with open(file_path, 'rb') as f:\n",
        "            pdf_reader = PyPDF2.PdfReader(f)\n",
        "            text = ''\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            documents.append(Document(text, metadata))\n",
        "\n",
        "    # テキストファイルを読み込む\n",
        "    elif filename.endswith('.txt'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            documents.append(Document(text, metadata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4azKtNLMb6Kc"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duuXVCZlwPst",
        "outputId": "32c5fa8d-7a1c-43f8-916e-6f2562a3c01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. プロフェッサーGilbert StrangのYouTube講座で学習した線形代数の授業「1. The Geometry of Linear Equations」の主要な要点は何ですか？\n",
            "2. 教科書p.62〜p.106ページで学習した行列についての主要な概念と要点は何ですか？\n",
            "3. 単純パーセプトロンが𝒚=𝒘$𝒙+𝑏を表すことができるという事実の意味は何ですか？\n",
            "4. バイアス項(+𝑏)がない表現、すなわち𝒚=𝒘$𝒙をどのように式表現すればよいですか？\n",
            "5. マンハッタン距離、ユークリッド距離、チェビシェフ距離を整理した上でマハラノビス距離をどのように説明しますか？\n",
            "6. 行列の写像の合成について詳しく説明してください。\n",
            "7. 線形変換fやgの合成写像をどのようにして表現しますか？\n",
            "8. 線形写像の核(Kerf)とその意義について詳しく説明してください。\n",
            "9. scipy.linalg.null_space(A)を使用してKerfの基底やその次元をどのように計算しますか？\n",
            "10. 線形代数の学習を通じて何らかのアプリケーションを構築する際に何らかのベクトルや行列をどのように使用しますか？\n"
          ]
        }
      ],
      "source": [
        "# 質問を作成するために invoke メソッドを使用\n",
        "questions = qa.invoke(\"この文章の中で重要と思う線形代数に関する内容についてを考える質問を10個考えてください\")\n",
        "\n",
        "# 結果の表示\n",
        "print(questions['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuiXiS92vWju",
        "outputId": "4158a9a3-293b-459c-9b7a-f73d53741500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "申し訳ありませんが、提供された文脈内には疑似逆行列についての情報は含まれておらず、そのため詳細について解説することはできません。\n"
          ]
        }
      ],
      "source": [
        "# 質問を作成するために invoke メソッドを使用\n",
        "questions = qa.invoke(\"疑似逆行列とは何ですか？検索できなければわからないと答えてください。\")\n",
        "\n",
        "# 結果の表示\n",
        "print(questions['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "wh0jw-neN2kc",
        "outputId": "873ea5fa-4254-4c4b-f17f-598134f05af0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Takayama Ryuji\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://ecab908476544743ce.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ecab908476544743ce.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# インポート\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import VectorDBQA, RetrievalQA\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# ドキュメントをロード\n",
        "dir_path = r\"C:\\Users\\Takayama Ryuji\\Desktop\\g9\\loadtext\\loadtext\"\n",
        "\n",
        "documents = []\n",
        "\n",
        "for filename in os.listdir(dir_path):\n",
        "    file_path = os.path.join(dir_path, filename)\n",
        "    metadata = {'filename': filename}\n",
        "\n",
        "    # PDFファイルを読み込む\n",
        "    if filename.endswith('.pdf'):\n",
        "        with open(file_path, 'rb') as f:\n",
        "            pdf_reader = PyPDF2.PdfReader(f)\n",
        "            text = ''\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            documents.append(Document(text, metadata))\n",
        "\n",
        "    # テキストファイルを読み込む\n",
        "    elif filename.endswith('.txt'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            documents.append(Document(text, metadata))\n",
        "\n",
        "\n",
        "# ドキュメントの分割とベクトルDBの作成\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# QAチェーンの作成\n",
        "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "\n",
        "# チャット機能の実装\n",
        "def chat_with_ai(input_text):\n",
        "    response = qa.invoke(input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。')\n",
        "    return response['result']\n",
        "\n",
        "# Gradioインターフェースの設定\n",
        "iface = gr.Interface(\n",
        "    fn=chat_with_ai,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Chat with Gradio\",\n",
        "    description=\"OpenAIを使ったチャットインターフェース\"\n",
        ")\n",
        "\n",
        "# インターフェースの起動\n",
        "iface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "collapsed": true,
        "id": "1DBYaPehIXn4",
        "outputId": "3edffb02-9af0-4715-b364-c279fe41b327"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takayama Ryuji\\AppData\\Local\\Temp\\ipykernel_22460\\4049497658.py:58: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
            "c:\\Users\\Takayama Ryuji\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* Running on public URL: https://636aa1e776e4a9df57.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://636aa1e776e4a9df57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takayama Ryuji\\AppData\\Local\\Temp\\ipykernel_22460\\4049497658.py:53: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = qa({\"query\": input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。'})\n"
          ]
        }
      ],
      "source": [
        "# インポート\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import VectorDBQA, RetrievalQA\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# ドキュメントをロードするクラス\n",
        "class Document:\n",
        "    def __init__(self, text, metadata):\n",
        "        self.page_content = text\n",
        "        self.metadata = metadata\n",
        "\n",
        "# ドキュメントをロード（例としてテキストを使用）\n",
        "dir_path = r\"C:\\Users\\Takayama Ryuji\\Desktop\\g9\\loadtext\\loadtext\"\n",
        "\n",
        "documents = []\n",
        "\n",
        "for filename in os.listdir(dir_path):\n",
        "    file_path = os.path.join(dir_path, filename)\n",
        "    metadata = {'filename': filename}\n",
        "\n",
        "    # PDFファイルを読み込む\n",
        "    if filename.endswith('.pdf'):\n",
        "        with open(file_path, 'rb') as f:\n",
        "            pdf_reader = PyPDF2.PdfReader(f)\n",
        "            text = ''\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            documents.append(Document(text, metadata))\n",
        "\n",
        "    # テキストファイルを読み込む\n",
        "    elif filename.endswith('.txt'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            documents.append(Document(text, metadata))\n",
        "\n",
        "# ドキュメントの分割とベクトルDBの作成\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# QAチェーンの作成\n",
        "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "\n",
        "# チャット機能の実装\n",
        "def chat_with_ai(input_text, history):\n",
        "    response = qa({\"query\": input_text+'検索できた範囲で答えてください。検索できないものは「わかりません」と答えてください。'})\n",
        "    return response['result']\n",
        "\n",
        "# GradioのChatInterfaceを使用してインターフェースを作成\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\n",
        "    gr.Markdown(\"### AI Chat with Gradio\")\n",
        "\n",
        "# インターフェースの起動\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
