{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"cells\": [\n",
    "      {\n",
    "         \"cell_type\": \"markdown\",\n",
    "         \"metadata\": {\n",
    "            \"id\": \"Yx76qjaGKwIS\"\n",
    "         },\n",
    "         \"source\": [\n",
    "            \"# æ—¢å­˜è³‡æ–™ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œæˆã™ã‚‹(Retrieval Augumented Generation:RAG)\\n\",\n",
    "            \"\\n\",\n",
    "            \"- å‚è€ƒ\\n\",\n",
    "            \"  - https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb\\n\",\n",
    "            \"  - https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\\n\",\n",
    "            \"  - https://note.com/mahlab/n/nb6677d0fc7c2\\n\",\n",
    "            \"- ChromadbãŒã™ã”ã„\\n\",\n",
    "            \"  - https://www.trychroma.com/\\n\",\n",
    "            \"  - https://github.com/chroma-core/chroma\\n\",\n",
    "            \"- ChatGPTã®Surveyè«–æ–‡\\n\",\n",
    "            \"  - https://arxiv.org/pdf/2304.01852.pdf\\n\",\n",
    "            \"  \\n\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 1,\n",
    "         \"metadata\": {\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 6477,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744862988591,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"fC7q6QnDPIW2\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"ename\": \"ModuleNotFoundError\",\n",
    "               \"evalue\": \"No module named 'chromadb'\",\n",
    "               \"output_type\": \"error\",\n",
    "               \"traceback\": [\n",
    "                  \"\\u001b[1;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "                  \"\\u001b[1;31mModuleNotFoundError\\u001b[0m                       Traceback (most recent call last)\",\n",
    "                  \"Cell \\u001b[1;32mIn[1], line 12\\u001b[0m\\n\\u001b[0;32m     10\\u001b[0m \\u001b[38;5;66;03m# langchain-openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\u001b[39;00m\\n\\u001b[0;32m     11\\u001b[0m \\u001b[38;5;28;01mfrom\\u001b[39;00m \\u001b[38;5;21;01mlangchain_openai\\u001b[39;00m \\u001b[38;5;28;01mimport\\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\\n\\u001b[1;32m---> 12\\u001b[0m \\u001b[38;5;28;01mimport\\u001b[39;00m \\u001b[38;5;21;01mchromadb\\u001b[39;00m\\n\\u001b[0;32m     13\\u001b[0m chroma_client \\u001b[38;5;241m=\\u001b[39m chromadb\\u001b[38;5;241m.\\u001b[39mClient()\\n\",\n",
    "                  \"\\u001b[1;31mModuleNotFoundError\\u001b[0m: No module named 'chromadb'\"\n",
    "               ]\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"from langchain.vectorstores import Chroma\\n\",\n",
    "            \"from langchain.embeddings import OpenAIEmbeddings\\n\",\n",
    "            \"from langchain.text_splitter import RecursiveCharacterTextSplitter\\n\",\n",
    "            \"from langchain.llms import OpenAI\\n\",\n",
    "            \"from langchain.chains import VectorDBQA, RetrievalQA\\n\",\n",
    "            \"from langchain.chat_models import ChatOpenAI\\n\",\n",
    "            \"from langchain.document_loaders import TextLoader, PyPDFLoader\\n\",\n",
    "            \"import openai\\n\",\n",
    "            \"import os\\n\",\n",
    "            \"# langchain-openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\n\",\n",
    "            \"from langchain_openai import OpenAIEmbeddings, ChatOpenAI\\n\",\n",
    "            \"import chromadb\\n\",\n",
    "            \"chroma_client = chromadb.Client()\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 2,\n",
    "         \"metadata\": {},\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"data\": {\n",
    "                  \"text/plain\": [\n",
    "                     \"True\"\n",
    "                  ]\n",
    "               },\n",
    "               \"execution_count\": 2,\n",
    "               \"metadata\": {},\n",
    "               \"output_type\": \"execute_result\"\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"from dotenv import load_dotenv\\n\",\n",
    "            \"load_dotenv()\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 3,\n",
    "         \"metadata\": {\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 3,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744862993307,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"SZEvBNCdPxmp\"\n",
    "         },\n",
    "         \"outputs\": [],\n",
    "         \"source\": [\n",
    "            \"openai.api_key = os.getenv(\\\"OPENAI_API_KEY\\\")\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 4,\n",
    "         \"metadata\": {\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 18069,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744863035248,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"1RVC0SOUL1Dp\"\n",
    "         },\n",
    "         \"outputs\": [],\n",
    "         \"source\": [\n",
    "            \"import os\\n\",\n",
    "            \"import PyPDF2\\n\",\n",
    "            \"\\n\",\n",
    "            \"class Document:\\n\",\n",
    "            \"    def __init__(self, text, metadata):\\n\",\n",
    "            \"        self.page_content = text\\n\",\n",
    "            \"        self.metadata = metadata\\n\",\n",
    "            \"\\n\",\n",
    "            \"dir_path = \\\"loadtext/\\\"\\n\",\n",
    "            \"\\n\",\n",
    "            \"documents = []\\n\",\n",
    "            \"\\n\",\n",
    "            \"for filename in os.listdir(dir_path):\\n\",\n",
    "            \"    file_path = os.path.join(dir_path, filename)\\n\",\n",
    "            \"    metadata = {'filename': filename}\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    if filename.endswith('.pdf'):\\n\",\n",
    "            \"        with open(file_path, 'rb') as f:\\n\",\n",
    "            \"            pdf_reader = PyPDF2.PdfReader(f)\\n\",\n",
    "            \"            text = ''\\n\",\n",
    "            \"            for page_num in range(len(pdf_reader.pages)):\\n\",\n",
    "            \"                page = pdf_reader.pages[page_num]\\n\",\n",
    "            \"                text += page.extract_text()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    elif filename.endswith('.txt'):\\n\",\n",
    "            \"        with open(file_path, 'r', encoding='utf-8') as f:\\n\",\n",
    "            \"            text = f.read()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 5,\n",
    "         \"metadata\": {\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 3637,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744863063789,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"oamHbgKbRBFI\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"ename\": \"NameError\",\n",
    "               \"evalue\": \"name 'documents' is not defined\",\n",
    "               \"output_type\": \"error\",\n",
    "               \"traceback\": [\n",
    "                  \"\\u001b[1;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "                  \"\\u001b[1;31mNameError\\u001b[0m                                 Traceback (most recent call last)\",\n",
    "                  \"Cell \\u001b[1;32mIn[2], line 2\\u001b[0m\\n\\u001b[0;32m      1\\u001b[0m text_splitter \\u001b[38;5;241m=\\u001b[39m RecursiveCharacterTextSplitter(chunk_size\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;241m1000\\u001b[39m, chunk_overlap\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;241m0\\u001b[39m)\\n\\u001b[1;32m----> 2\\u001b[0m texts \\u001b[38;5;241m=\\u001b[39m text_splitter\\u001b[38;5;241m.\\u001b[39msplit_documents(documents)\\n\\u001b[0;32m      3\\u001b[0m embeddings \\u001b[38;5;241m=\\u001b[39m OpenAIEmbeddings()\\n\\u001b[0;32m      4\\u001b[0m vectordb \\u001b[38;5;241m=\\u001b[39m Chroma\\u001b[38;5;241m.\\u001b[39mfrom_documents(texts, embeddings)\\n\",\n",
    "                  \"\\u001b[1;31mNameError\\u001b[0m: name 'documents' is not defined\"\n",
    "               ]\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\n\",\n",
    "            \"texts = text_splitter.split_documents(documents)\\n\",\n",
    "            \"embeddings = OpenAIEmbeddings()\\n\",\n",
    "            \"vectordb = Chroma.from_documents(texts, embeddings)\\n\",\n",
    "            \"\\n\",\n",
    "            \"qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\\\"gpt-4\\\"), chain_type=\\\"stuff\\\", retriever=vectordb.as_retriever())\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 6,\n",
    "         \"metadata\": {\n",
    "            \"colab\": {\n",
    "               \"base_uri\": \"https://localhost:8080/\"\n",
    "            },\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 14384,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744863080365,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"duuXVCZlwPst\",\n",
    "            \"outputId\": \"8af590ce-4923-438d-e7cd-179db285c54f\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"name\": \"stdout\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"1. ç·šå½¢ä»£æ•°ã«ãŠã„ã¦ã€ãƒ™ã‚¯ãƒˆãƒ«ã¨ã¯ä½•ã‚’æŒ‡ã—ã¾ã™ã‹ï¼Ÿ\\n\",\n",
    "                  \"2. ç·šå½¢å†™åƒã¨ã¯ä½•ã§ã™ã‹ï¼Ÿå…·ä½“çš„ãªä¾‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\\n\",\n",
    "                  \"3. ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã™ã‚‹ç·šå½¢å¤‰æ›ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\\n\",\n",
    "                  \"4. 'ğ‘“(ğ’™)'ã¨ 'ğ‘”(ğ‘“ğ’™)'ã®é•ã„ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\\n\",\n",
    "                  \"5. ç·šå½¢ä»£æ•°ã®ä¸­ã§ã€å†™åƒã®åˆæˆã¨ã¯ä½•ã‚’æŒ‡ã—ã¾ã™ã‹ï¼Ÿ\\n\",\n",
    "                  \"6. 'ğ¾ğ‘’ğ‘Ÿğ‘“'ã¨ã¯ä½•ã‚’æ„å‘³ã—ã¾ã™ã‹ï¼Ÿ\\n\",\n",
    "                  \"7. 'ğ‘‘ğ‘–ğ‘šğ‘‰=dimğ¾ğ‘’ğ‘Ÿğ‘“+dim(ğ¼ğ‘šğ‘“)'ã¨ã„ã†ç­‰å¼ã®æ„å‘³ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\\n\",\n",
    "                  \"8. ç·šå½¢ä»£æ•°ã«ãŠã‘ã‚‹é€£ç¶šã—ãŸä¸€æ¬¡æ–¹ç¨‹å¼ã®è§£ãæ–¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\\n\",\n",
    "                  \"9. ç·šå½¢ä»£æ•°ã‚’æ´»ç”¨ã—ãŸãƒªã‚¢ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä½•ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ\\n\",\n",
    "                  \"10. Pythonã§ç·šå½¢ä»£æ•°ã®å•é¡Œã‚’è§£ãéš›ã®ä¸€èˆ¬çš„ãªæ‰‹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\\n\"\n",
    "               ]\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"# è³ªå•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã« invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨\\n\",\n",
    "            \"questions = qa.invoke(\\\"ã“ã®æ–‡ç« ã®ä¸­ã§é‡è¦ã©æ€ã†ç·šå½¢ä»£æ•°ã«é–¢ã™ã‚‹å†…å®¹ã«ã¤ã„ã¦ã‚’è€ƒãˆã‚‹è³ªå•ã‚’10å€‹è€ƒãˆã¦ãã ã•ã„\\\")\\n\",\n",
    "            \"\\n\",\n",
    "            \"# çµæœã®è¡¨ç¤º\\n\",\n",
    "            \"print(questions['result'])\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 7,\n",
    "         \"metadata\": {\n",
    "            \"colab\": {\n",
    "               \"base_uri\": \"https://localhost:8080/\"\n",
    "            },\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 4227,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744863124931,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"WuiXiS92vWju\",\n",
    "            \"outputId\": \"9c8efc9e-76ec-450a-f479-ef2af65b4efe\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"name\": \"stdout\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"ç§ã¯ç–‘ä¼¼é€†è¡Œåˆ—ã«ã¤ã„ã¦ã®å…·ä½“çš„ãªçŸ¥è­˜ã‚’æŒã£ã¦ã„ã¾ã›ã‚“ã€‚æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ããªã„ãŸã‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®ç†ç”±ã‹ã‚‰è©³ç´°ãªèª¬æ˜ã¯æä¾›ã§ãã¾ã›ã‚“ã€‚ã‚ãªãŸã®è³ªå•ã«å¯¾ã™ã‚‹ç–‘ä¼¼é€†è¡Œåˆ—ã®è©³ç´°ãªèª¬æ˜ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€ä¿¡é ¼ã§ãã‚‹è³‡æ–™ã‚„å‚è€ƒæ›¸ç±ã‚’èª¿ã¹ã¦ã¿ã¦ãã ã•ã„ã€‚\\n\"\n",
    "               ]\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"# è³ªå•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã« invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨\\n\",\n",
    "            \"questions = qa.invoke(\\\"ç–‘ä¼¼é€†è¡Œåˆ—ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿæ¤œç´¢ã§ããªã‘ã‚Œã°ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\\\")\\n\",\n",
    "            \"\\n\",\n",
    "            \"# çµæœã®è¡¨ç¤º\\n\",\n",
    "            \"print(questions['result'])\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": null,\n",
    "         \"metadata\": {\n",
    "            \"colab\": {\n",
    "               \"base_uri\": \"https://localhost:8080/\",\n",
    "               \"height\": 614\n",
    "            },\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 15160,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1744863145195,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05483787995557177837\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"wh0jw-neN2kc\",\n",
    "            \"outputId\": \"ba4b2d47-dad7-45da-afb8-fbb12ce02f64\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"name\": \"stderr\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"/Users/yamadayuuhei/ç ”ç©¶/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\\n\",\n",
    "                  \"  from .autonotebook import tqdm as notebook_tqdm\\n\"\n",
    "               ]\n",
    "            },\n",
    "            {\n",
    "               \"name\": \"stdout\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"* Running on local URL:  http://127.0.0.1:7860\\n\",\n",
    "                  \"* Running on public URL: https://281b2fb5562b54719d.gradio.live\\n\",\n",
    "                  \"\\n\",\n",
    "                  \"This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\\n\"\n",
    "               ]\n",
    "            },\n",
    "            {\n",
    "               \"data\": {\n",
    "                  \"text/html\": [\n",
    "                     \"<div><iframe src=\\\"https://281b2fb5562b54719d.gradio.live\\\" width=\\\"100%\\\" height=\\\"500\\\" allow=\\\"autoplay; camera; microphone; clipboard-read; clipboard-write;\\\" frameborder=\\\"0\\\" allowfullscreen></iframe></div>\"\n",
    "                  ],\n",
    "                  \"text/plain\": [\n",
    "                     \"<IPython.core.display.HTML object>\"\n",
    "                  ]\n",
    "               },\n",
    "               \"metadata\": {},\n",
    "               \"output_type\": \"display_data\"\n",
    "            },\n",
    "            {\n",
    "               \"data\": {\n",
    "                  \"text/plain\": []\n",
    "               },\n",
    "               \"execution_count\": 8,\n",
    "               \"metadata\": {},\n",
    "               \"output_type\": \"execute_result\"\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\n\",\n",
    "            \"from langchain.vectorstores import Chroma\\n\",\n",
    "            \"from langchain.text_splitter import Rec1ursiveCharacterTextSplitter\\n\",\n",
    "            \"from langchain.chains import VectorDBQA, RetrievalQA\\n\",\n",
    "            \"from langchain.document_loaders import TextLoader, PyPDFLoader\\n\",\n",
    "            \"from langchain_openai import OpenAIEmbeddings, ChatOpenAI\\n\",\n",
    "            \"import gradio as gr\\n\",\n",
    "            \"import openai\\n\",\n",
    "            \"import os\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰\\n\",\n",
    "            \"dir_path = 'loadtext/'\\n\",\n",
    "            \"\\n\",\n",
    "            \"documents = []\\n\",\n",
    "            \"\\n\",\n",
    "            \"for filename in os.listdir(dir_path):\\n\",\n",
    "            \"    file_path = os.path.join(dir_path, filename)\\n\",\n",
    "            \"    metadata = {'filename': filename}\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    if filename.endswith('.pdf'):\\n\",\n",
    "            \"        with open(file_path, 'rb') as f:\\n\",\n",
    "            \"            pdf_reader = PyPDF2.PdfReader(f)\\n\",\n",
    "            \"            text = ''\\n\",\n",
    "            \"            for page_num in range(len(pdf_reader.pages)):\\n\",\n",
    "            \"                page = pdf_reader.pages[page_num]\\n\",\n",
    "            \"                text += page.extract_text()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    elif filename.endswith('.txt'):\\n\",\n",
    "            \"        with open(file_path, 'r', encoding='utf-8') as f:\\n\",\n",
    "            \"            text = f.read()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\",\n",
    "            \"\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®ä½œæˆ\\n\",\n",
    "            \"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\n\",\n",
    "            \"texts = text_splitter.split_documents(documents)\\n\",\n",
    "            \"embeddings = OpenAIEmbeddings()\\n\",\n",
    "            \"vectordb = Chroma.from_documents(texts, embeddings)\\n\",\n",
    "            \"\\n\",\n",
    "            \"# QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ\\n\",\n",
    "            \"qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\\\"gpt-4\\\"), chain_type=\\\"stuff\\\", retriever=vectordb.as_retriever())\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…\\n\",\n",
    "            \"def chat_with_ai(input_text):\\n\",\n",
    "            \"    response = qa.invoke(input_text+'æ¤œç´¢ã§ããŸç¯„å›²ã§ç­”ãˆã¦ãã ã•ã„ã€‚æ¤œç´¢ã§ããªã„ã‚‚ã®ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚')\\n\",\n",
    "            \"    return response['result']\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¨­å®š\\n\",\n",
    "            \"iface = gr.Interface(\\n\",\n",
    "            \"    fn=chat_with_ai,\\n\",\n",
    "            \"    inputs=\\\"text\\\",\\n\",\n",
    "            \"    outputs=\\\"text\\\",\\n\",\n",
    "            \"    title=\\\"AI Chat with Gradio\\\",\\n\",\n",
    "            \"    description=\\\"OpenAIã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\\\"\\n\",\n",
    "            \")\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•\\n\",\n",
    "            \"iface.launch(share=True)\"\n",
    "         ]\n",
    "      },\n",
    "      {\n",
    "         \"cell_type\": \"code\",\n",
    "         \"execution_count\": 9,\n",
    "         \"metadata\": {\n",
    "            \"colab\": {\n",
    "               \"base_uri\": \"https://localhost:8080/\",\n",
    "               \"height\": 592\n",
    "            },\n",
    "            \"executionInfo\": {\n",
    "               \"elapsed\": 11785,\n",
    "               \"status\": \"ok\",\n",
    "               \"timestamp\": 1721112692893,\n",
    "               \"user\": {\n",
    "                  \"displayName\": \"ä¸­è¥¿å´‡æ–‡\",\n",
    "                  \"userId\": \"05356289898840747459\"\n",
    "               },\n",
    "               \"user_tz\": -540\n",
    "            },\n",
    "            \"id\": \"1DBYaPehIXn4\",\n",
    "            \"outputId\": \"41675b6c-0c96-4446-e22f-25ab82f6b930\"\n",
    "         },\n",
    "         \"outputs\": [\n",
    "            {\n",
    "               \"name\": \"stderr\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"/var/folders/nq/n3nkdz2558g2zjbwzth6xy700000gn/T/ipykernel_73588/350495278.py:58: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\\n\",\n",
    "                  \"  chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\\n\",\n",
    "                  \"/Users/yamadayuuhei/ç ”ç©¶/Nakanishi_Lab/AIME-based-Explanation-System-for-ChatGPT-Outputs/AIME-based-Explanation-System/lib/python3.13/site-packages/gradio/chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\\n\",\n",
    "                  \"  warnings.warn(\\n\"\n",
    "               ]\n",
    "            },\n",
    "            {\n",
    "               \"name\": \"stdout\",\n",
    "               \"output_type\": \"stream\",\n",
    "               \"text\": [\n",
    "                  \"* Running on local URL:  http://127.0.0.1:7861\\n\",\n",
    "                  \"* Running on public URL: https://a6aed4215b1e517d29.gradio.live\\n\",\n",
    "                  \"\\n\",\n",
    "                  \"This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\\n\"\n",
    "               ]\n",
    "            },\n",
    "            {\n",
    "               \"data\": {\n",
    "                  \"text/html\": [\n",
    "                     \"<div><iframe src=\\\"https://a6aed4215b1e517d29.gradio.live\\\" width=\\\"100%\\\" height=\\\"500\\\" allow=\\\"autoplay; camera; microphone; clipboard-read; clipboard-write;\\\" frameborder=\\\"0\\\" allowfullscreen></iframe></div>\"\n",
    "                  ],\n",
    "                  \"text/plain\": [\n",
    "                     \"<IPython.core.display.HTML object>\"\n",
    "                  ]\n",
    "               },\n",
    "               \"metadata\": {},\n",
    "               \"output_type\": \"display_data\"\n",
    "            },\n",
    "            {\n",
    "               \"data\": {\n",
    "                  \"text/plain\": []\n",
    "               },\n",
    "               \"execution_count\": 9,\n",
    "               \"metadata\": {},\n",
    "               \"output_type\": \"execute_result\"\n",
    "            }\n",
    "         ],\n",
    "         \"source\": [\n",
    "            \"# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\n\",\n",
    "            \"from langchain.vectorstores import Chroma\\n\",\n",
    "            \"from langchain.text_splitter import RecursiveCharacterTextSplitter\\n\",\n",
    "            \"from langchain.chains import VectorDBQA, RetrievalQA\\n\",\n",
    "            \"from langchain.document_loaders import TextLoader, PyPDFLoader\\n\",\n",
    "            \"from langchain_openai import OpenAIEmbeddings, ChatOpenAI\\n\",\n",
    "            \"import gradio as gr\\n\",\n",
    "            \"import openai\\n\",\n",
    "            \"import os\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹\\n\",\n",
    "            \"class Document:\\n\",\n",
    "            \"    def __init__(self, text, metadata):\\n\",\n",
    "            \"        self.page_content = text\\n\",\n",
    "            \"        self.metadata = metadata\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹ã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰\\n\",\n",
    "            \"dir_path = 'loadtext2'\\n\",\n",
    "            \"\\n\",\n",
    "            \"documents = []\\n\",\n",
    "            \"\\n\",\n",
    "            \"for filename in os.listdir(dir_path):\\n\",\n",
    "            \"    file_path = os.path.join(dir_path, filename)\\n\",\n",
    "            \"    metadata = {'filename': filename}\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    if filename.endswith('.pdf'):\\n\",\n",
    "            \"        with open(file_path, 'rb') as f:\\n\",\n",
    "            \"            pdf_reader = PyPDF2.PdfReader(f)\\n\",\n",
    "            \"            text = ''\\n\",\n",
    "            \"            for page_num in range(len(pdf_reader.pages)):\\n\",\n",
    "            \"                page = pdf_reader.pages[page_num]\\n\",\n",
    "            \"                text += page.extract_text()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\",\n",
    "            \"\\n\",\n",
    "            \"    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\\n\",\n",
    "            \"    elif filename.endswith('.txt'):\\n\",\n",
    "            \"        with open(file_path, 'r', encoding='utf-8') as f:\\n\",\n",
    "            \"            text = f.read()\\n\",\n",
    "            \"            documents.append(Document(text, metadata))\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®ä½œæˆ\\n\",\n",
    "            \"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\n\",\n",
    "            \"texts = text_splitter.split_documents(documents)\\n\",\n",
    "            \"embeddings = OpenAIEmbeddings()\\n\",\n",
    "            \"vectordb = Chroma.from_documents(texts, embeddings)\\n\",\n",
    "            \"\\n\",\n",
    "            \"# QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ\\n\",\n",
    "            \"qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\\\"gpt-4\\\"), chain_type=\\\"stuff\\\", retriever=vectordb.as_retriever())\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…\\n\",\n",
    "            \"def chat_with_ai(input_text, history):\\n\",\n",
    "            \"    response = qa({\\\"query\\\": input_text+'æ¤œç´¢ã§ããŸç¯„å›²ã§ç­”ãˆã¦ãã ã•ã„ã€‚æ¤œç´¢ã§ããªã„ã‚‚ã®ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚'})\\n\",\n",
    "            \"    return response['result']\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Gradioã®ChatInterfaceã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆ\\n\",\n",
    "            \"with gr.Blocks() as demo:\\n\",\n",
    "            \"    chatbot = gr.ChatInterface(fn=chat_with_ai, chatbot=gr.Chatbot())\\n\",\n",
    "            \"    gr.Markdown(\\\"### AI Chat with Gradio\\\")\\n\",\n",
    "            \"\\n\",\n",
    "            \"# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•\\n\",\n",
    "            \"demo.launch(share=True)\"\n",
    "         ]\n",
    "      }\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "      \"colab\": {\n",
    "         \"authorship_tag\": \"ABX9TyMfrYF6ow3Du/BqoD+S8ar9\",\n",
    "         \"provenance\": []\n",
    "      },\n",
    "      \"kernelspec\": {\n",
    "         \"display_name\": \".venv\",\n",
    "         \"language\": \"python\",\n",
    "         \"name\": \"python3\"\n",
    "      },\n",
    "      \"language_info\": {\n",
    "         \"codemirror_mode\": {\n",
    "            \"name\": \"ipython\",\n",
    "            \"version\": 3\n",
    "         },\n",
    "         \"file_extension\": \".py\",\n",
    "         \"mimetype\": \"text/x-python\",\n",
    "         \"name\": \"python\",\n",
    "         \"nbconvert_exporter\": \"python\",\n",
    "         \"pygments_lexer\": \"ipython3\",\n",
    "         \"version\": \"3.12.9\"\n",
    "      }\n",
    "   },\n",
    "   \"nbformat\": 4,\n",
    "   \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
